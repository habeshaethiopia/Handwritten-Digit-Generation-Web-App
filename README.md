# Handwritten Digit Generation Web App

This repository contains the code for a web application that generates images of handwritten digits (0-9) using a custom-trained Conditional Generative Adversarial Network (CGAN). The user can select a specific digit, and the app will generate five unique images of that digit, displayed in a format similar to the MNIST dataset.

This project was developed as a solution to "Problem 3 (Handwritten Digit Generation Web App)" from a technical assessment.

## Table of Contents

- [Live Demo](#live-demo)
- [Features](#features)
- [Model Training](#model-training)
  - [Dataset](#dataset)
  - [Architecture](#architecture)
  - [Training Environment](#training-environment)
  - [Training Script](#training-script)
- [Web Application](#web-application)
  - [Framework](#framework)
  - [Deployment](#deployment)
- [Files in this Repository](#files-in-this-repository)
- [Setup and Run Locally](#setup-and-run-locally)
- [Contact](#contact)

## Live Demo

**[Insert Live Streamlit App Link Here]**

*The app is hosted on Streamlit Cloud and should be accessible for at least two weeks from June 23, 2025. It might enter a sleep mode when idle but will reactivate upon access.*

## Features

* **Digit Selection:** Users can easily select any digit from 0 to 9 using a dropdown menu.
* **Image Generation:** On command, the app generates 5 distinct handwritten images of the selected digit.
* **MNIST-like Display:** The generated images are displayed clearly in a grid, mimicking the visual style of the MNIST dataset.
* **Custom Trained Model:** The generation is powered by a Conditional GAN trained from scratch on the MNIST dataset.

## Model Training

The core of this application is a Conditional Generative Adversarial Network (CGAN) trained to understand and generate specific handwritten digits.

### Dataset

The model was trained exclusively on the **MNIST (Modified National Institute of Standards and Technology) dataset**.
* **Image Format:** 28x28 pixel grayscale images.
* **Content:** Images of handwritten digits from 0 to 9.

### Architecture

The CGAN consists of two main components:

1.  **Generator (G):**
    * **Input:** A random latent noise vector (100 dimensions) concatenated with a 10-dimensional embedding of the desired digit label (0-9).
    * **Architecture:** Utilizes fully connected layers followed by `nn.ConvTranspose2d` (deconvolutional layers) to upsample the combined input into a 28x28 grayscale image. Batch normalization and ReLU activations are used throughout, with a final Tanh activation to output pixel values in the range \[-1, 1].
    * **Purpose:** To learn the distribution of real handwritten digits conditioned on a given label, and generate new, convincing fake images.

2.  **Discriminator (D):**
    * **Input:** A 28x28 grayscale image concatenated with a tiled 10-dimensional embedding of its corresponding digit label across its channels.
    * **Architecture:** Employs `nn.Conv2d` layers to downsample the input image-label combination. LeakyReLU activations and batch normalization are used. A final linear layer outputs a single scalar representing the probability that the input image is real and matches the given label.
    * **Purpose:** To distinguish between real images from the MNIST dataset and fake images generated by the Generator, also ensuring the image matches the provided label.

### Training Environment

The model was trained using **Google Colab** with a **T4 GPU**, ensuring efficient computation while adhering to the specified resource constraints. No pre-trained model weights were used.

### Training Script

The training process is detailed in the `cgan_mnist_train.py` (or Jupyter Notebook equivalent) file.

* **Framework:** PyTorch
* **Loss Function:** `nn.BCEWithLogitsLoss()` for both Generator and Discriminator, which is numerically stable for GAN training.
* **Optimizers:** `torch.optim.Adam` with specific learning rates (`LR_G = 0.0002`, `LR_D = 0.0002`) and `beta1 = 0.5`.
* **Training Process:** Standard GAN adversarial training loop, where the Discriminator is trained to correctly classify real vs. fake images (and their labels), and the Generator is trained to fool the Discriminator.
* **Output:** The trained Generator's weights are saved as `generator_cgan.pth`.

## Web Application

### Framework

The web application is built using **Streamlit**, a powerful framework that allows for the rapid creation and deployment of interactive data applications in Python.

### Deployment

The application is deployed on **Streamlit Cloud**. This platform automatically handles environment setup, dependency installation (from `requirements.txt`), and provides a public URL. It features a "sleep mode" to conserve resources when idle, reactivating upon user access.

## Files in this Repository

* `app.py`: The main Streamlit web application script. This file loads the trained model and handles the UI and image generation logic.
* `cgan_mnist_train.py`: The Python script (or equivalent content from a Colab notebook) used for training the Conditional GAN model on the MNIST dataset. It defines the Generator and Discriminator architectures and the training loop.
* `generator_cgan.pth`: The saved state dictionary (weights) of the trained Generator model. This file is crucial for the `app.py` to function.
* `requirements.txt`: A list of Python packages required to run the Streamlit application (and for training).

## Setup and Run Locally

To run this application on your local machine:

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/digit_generator_app.git](https://github.com/your-username/digit_generator_app.git)
    cd digit_generator_app
    ```
    *(Replace `your-username/digit_generator_app.git` with your actual GitHub repository URL)*

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ensure the model file exists:** Make sure `generator_cgan.pth` is present in the same directory as `app.py`. If you trained it yourself, download it from your Colab session.

5.  **Run the Streamlit app:**
    ```bash
    streamlit run app.py
    ```
    This will open the application in your web browser.
